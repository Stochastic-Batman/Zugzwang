\documentclass{article}

\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{array}
\usepackage{booktabs}
\usepackage{hyperref}
\usepackage{longtable}
\usepackage{tabularx}

\title{Chess Engine Tutorial}
\author{Stochastic Batman}
\date{February 14, 2026}

\newcommand{\E}{\mathbb{E}}
\newcommand{\s}{\mathcal{S}}
\newcommand{\argmax}{arg\,max}
\newcommand{\argmin}{arg\,min}

\algrenewcommand\algorithmicrequire{\textbf{Input:}}
\algrenewcommand\algorithmicensure{\textbf{Output:}}

\begin{document}
	\maketitle
	
	\begin{abstract}
		This tutorial provides a comprehensive guide to implementing a chess engine using modern algorithmic techniques. I cover fundamental data structures (bitboards and magic bitboards), search algorithms (minimax with alpha-beta pruning), move generation strategies (pseudo-legal with legal filtering), hashing techniques (Zobrist hashing), principal variation tracking, evaluation heuristics (piece-square tables), and move ordering optimizations. The material is suitable for programmers with knowledge of C and chess rules who wish to implement a functional engine from scratch. These notes synthesize information from \textit{Chess Programming Wiki} \cite{cpw}, Knuth and Moore's seminal work on alpha-beta \cite{knuth1975}, and practical implementation guides \cite{mediocrechess}. Gemini 3 Fast was used for grammar correction. For the implementation of this chess engine in \texttt{C}, check out \cite{repo}.
	\end{abstract}
	
	\section{Chess (Algebraic) Notation}
	
	\subsection*{Purpose}
	Chess notation is a standardized system for recording and describing chess moves. Understanding this notation is essential for implementing a chess engine that can communicate moves in a human-readable format. Throughout this document, all positions will be shown from White's perspective.
	
	\subsection*{Algebraic Notation}
	
	Algebraic notation is the most common system. Each square on the chessboard is identified by a coordinate system:
	
	\begin{itemize}
		\item \textbf{Files}: Columns labeled $a$ through $h$ from left to right.
		\item \textbf{Ranks}: Rows numbered $1$ through $8$ from bottom to top.
		\item \textbf{Squares}: Identified by concatenating file and rank, e.g., $e4$, $a1$, $h8$.
	\end{itemize}
	
	\subsection*{Piece Designation}
	
	Each piece type has a letter designation:
	
	\begin{itemize}
		\item \textbf{K} $\gets$ King
		\item \textbf{Q} $\gets$ Queen
		\item \textbf{R} $\gets$ Rook
		\item \textbf{B} $\gets$ Bishop
		\item \textbf{N} $\gets$ Knight (K is reserved for King)
		\item \textbf{(no letter)} $\gets$ Pawn
	\end{itemize}
	
	\subsection*{Move Notation Rules}
	
	A move is recorded using the following conventions, where $\circ$ denotes concatenation:
	
	\begin{enumerate}
		\item \textbf{Simple moves}: Piece letter $\circ$ destination square
		\begin{itemize}
			\item \textit{Example:} $Nf3$ means "Knight moves to $f3$".
			\item \textit{Example:} $e4$ means "pawn moves to $e4$".
		\end{itemize}
		
		\item \textbf{Captures}: Piece letter $\circ \, x \, \circ$ destination square
		\begin{itemize}
			\item \textit{Example:} $Bxc4$ means "Bishop captures on $c4$".
			\item \textit{Example:} $exd5$ means "pawn on $e$-file captures on $d5$".
			\item \textit{Note}: The $x$ symbol may be omitted in some notations, but definitely not in \cite{repo}.
		\end{itemize}
		
		\item \textbf{Castling}:
		\begin{itemize}
			\item O-O: Kingside castling (king and $h$-rook).
			\item O-O-O: Queenside castling (king and $a$-rook).
		\end{itemize}
		
		\item \textbf{Pawn promotion}: Destination square $\circ = \circ$ promoted piece
		\begin{itemize}
			\item \textit{Example:} $e8=Q$ means "pawn moves to $e8$ and promotes to Queen".
			\item \textit{Example:} $axb8=N$ means "pawn captures on $b8$ and promotes to Knight".
		\end{itemize}
		
		\item \textbf{En passant}: Recorded as normal pawn capture
		\begin{itemize}
			\item \textit{Example:} $exd6 \,\, e.p.$ (the notation $e.p.$ may be appended for clarity).
		\end{itemize}
		
		\item \textbf{Disambiguation}: When multiple pieces of the same type can move to the same square
		\begin{itemize}
			\item Add the file of origin: $Nbd7$ (Knight from $b$-file to $d7$).
			\item Add the rank of origin: $R1a3$ (Rook from rank $1$ to $a3$).
			\item Add both if necessary: $Qh4e1$ (Queen from $h4$ to $e1$).
		\end{itemize}
		
		\item \textbf{Check and checkmate annotations}:
		\begin{itemize}
			\item $+$: Check (king is under attack).
			\item \textit{Example:} $Nf7+$ means "Knight to $f7$, check".
			\item $\#$: Checkmate (king is in check with no legal moves).
			\item \textit{Example:} $Qh5\#$ means "Queen to $h5$, checkmate".
		\end{itemize}
	\end{enumerate}
	
	\subsection*{Two-Column Game Recording}
	
	Complete games are typically recorded with move numbers in a two-column format, with White's moves on the left and Black's moves on the right:
	
	\begin{center}
		\begin{tabular}{cll}
			\toprule
			\textbf{Move} & \textbf{White} & \textbf{Black} \\
			\midrule
			1 & e4 & e5 \\
			2 & Nf3 & Nc6 \\
			3 & Bb5 & a6 \\
			4 & Ba4 & Nf6 \\
			5 & O-O & Be7 \\
			\bottomrule
		\end{tabular}
	\end{center}
	
	This format clearly shows the sequence of play and is the standard used in chess databases and engine output.
	
	\section{Bitboards}
	
	\subsection*{Purpose}
	
	Bitboards are a highly efficient data structure for representing chess positions. Instead of using an 8$\times$8 array to store the board state, bitboards use 64-bit integers where each bit represents a square on the chessboard. This representation enables extremely fast bitwise operations for move generation, attack detection, and position evaluation. The performance gain comes from the ability to operate on multiple squares simultaneously using single CPU instructions.
	
	\subsection*{Formalism}
	
	Let $B \in \{0,1\}^{64}$ be a bitboard, represented as a 64-bit unsigned integer. Each bit position $i \in [0, 63]$ corresponds to a square on the chessboard, where:
	
	$$ i = 8r + f $$
	
	where $r \in [0,7]$ is the rank (row) and $f \in [0,7]$ is the file (column). The standard Little-Endian Rank-File (LERF) mapping is bit $0 \leftrightarrow a1$, bit $7 \leftrightarrow h1$, bit $56 \leftrightarrow a8$ and bit $63 \leftrightarrow h8$.
	
	\subsection*{Basic Bitwise Operations}
	
	\begin{enumerate}
		\item \textbf{Set bit at square $s$}:
		$$ B' = B \lor 2^s $$
		
		\item \textbf{Clear bit at square $s$}:
		$$ B' = B \land \neg(2^s) $$
		
		\item \textbf{Toggle bit at square $s$}:
		$$ B' = B \oplus 2^s $$
		
		\item \textbf{Test bit at square $s$}:
		$$
		\text{occupied}(s) = \begin{cases}
			\text{true} & \text{if } (B \land 2^s) \neq 0 \\
			\text{false} & \text{otherwise}
		\end{cases}
		$$
		
		\item \textbf{Population count} (count number of set bits):
		$$ |B| = \sum_{i=0}^{63} \left( \left\lfloor \frac{B}{2^i} \right\rfloor \bmod 2 \right) $$
		Modern CPUs implement this as a single instruction: \texttt{POPCNT}.
		
		\item \textbf{Least significant bit} (find lowest set bit):
		$$ \text{LSB}(B) = B \land (\neg B + 1) $$
		This isolates the rightmost 1-bit using two's complement arithmetic.
		
		\item \textbf{Remove least significant bit}:
		$$ B' = B \land (B - 1) $$
		This clears the rightmost 1-bit, useful for iterating through set bits.
		
		\item \textbf{Bit scan forward} (index of LSB):
		$$ \text{BSF}(B) = |(B \land (\neg B + 1)) - 1| $$
		Returns the index of the least significant set bit.
	\end{enumerate}
	
	\subsection*{Complete Board Representation}
	
	A complete chess position requires 12 piece bitboards (6 piece types $\times$ 2 colors):
	\begin{align}
		&\text{Let } \mathcal{P} = \{\stackrel{\text{(pawn)}}{P}, N, B, R, Q, K\} \text{ be the set of piece types} \\
		&\text{Let } \mathcal{C} = \{w, b\} \text{ be the set of colors (white, black)}
	\end{align}
	
	For each piece type $p \in \mathcal{P}$ and color $c \in \mathcal{C}$, we maintain:
	$$ B_{p,c} \in \{0,1\}^{64} $$
	
	Additionally, we maintain composite bitboards for efficiency:
	
	\begin{align}
		\text{Occupied}_w &:= \bigvee_{p \in \mathcal{P}} B_{p,w} \\
		\text{Occupied}_b &:= \bigvee_{p \in \mathcal{P}} B_{p,b} \\
		\text{O} &:= \text{Occupied}_w \lor \text{Occupied}_b
	\end{align}
	
	where $\bigvee$ denotes bitwise OR over all elements.
	
	\subsection*{Shift Operations for Piece Attacks}
	
	Directional shifts allow the engine to calculate piece movement across the entire board simultaneously using bitwise arithmetic. Because the board is 8 squares wide, vertical movement corresponds to a shift of 8 bits, while horizontal movement corresponds to a shift of 1 bit.
	
	\subsubsection*{The Wrapping Problem}
	
	Standard bit shifts do not respect the boundaries of an $8 \times 8$ grid. Without safety masks, bits on the edge of the board would \textit{wrap} to the opposite side:
	\begin{itemize}
		\item \textbf{Eastward wrapping}: A bit on the $h$-file, when shifted left by 1, would incorrectly appear on the $a$-file of the next rank.
		\item \textbf{Westward wrapping}: A bit on the $a$-file, when shifted right by 1, would appear on the $h$-file of the previous rank.
	\end{itemize}
	
	To prevent this, we use \textbf{File Masks} (All squares on the $a$ and $h$-files), usually represented in the hexadecimal format, to prune invalid moves that would otherwise cross the board's edge:
	\begin{align}
		\text{FileA} &:= \texttt{0x0101010101010101} \\
		\text{FileH} &:= \texttt{0x8080808080808080} \\
		\text{NorthOne}(B) &:= B \ll 8 \\
		\text{SouthOne}(B) &:= B \gg 8 \\
		\text{EastOne}(B) &:= (B \ll 1) \land \neg \text{FileA} \\
		\text{WestOne}(B) &:= (B \gg 1) \land \neg \text{FileH} \\
		\text{NorthEast}(B) &:= (B \ll 9) \land \neg \text{FileA} \\
		\text{NorthWest}(B) &:= (B \ll 7) \land \neg \text{FileH} \\
		\text{SouthEast}(B) &:= (B \gg 7) \land \neg \text{FileA} \\
		\text{SouthWest}(B) &:= (B \gg 9) \land \neg \text{FileH}
	\end{align}
	
	\section{Magic Bitboards}
	
	\subsection*{Purpose}
	
	Magic bitboards solve the computational challenge of generating sliding piece attacks (rooks, bishops, queens) efficiently. The naive approach of ray-casting is too slow for deep search. Magic bitboards use perfect hashing \cite{perfecthashing} to pre-compute all possible attack patterns and retrieve them in $O(1)$ time using a single multiplication and shift operation.
	
	\subsection*{The Sliding Piece Problem}
	
	Define the set of all square indices $\s = \{0, 1, \dots, 63\}$. For a sliding piece on square $s \in \s$, the attack pattern depends on the occupancy of squares along its movement rays. Let $\mathcal{R}_s$ be the set of movement rays (orthogonal for rooks, diagonal for bishops). For each ray $r \in \mathcal{R}_s$, let the squares on that ray be ordered by their distance from $s$ as $\{t_1, t_2, \dots, t_k\}$. The challenge is to compute (in constant time):
	$$
		A(s, O) := \bigcup_{r \in \mathcal{R}_s} \{ t_i \in r \mid \forall j < i, t_j \notin O \}
	$$
	
	where:
	\begin{itemize}
		\item $t_j \notin O$ denotes that square $t_j$ is empty (\texttt{B[$t_j$] = 0}).
		\item The condition $\forall j < i, t_j \notin O$ ensures that the ray continues until it hits the first occupied square (the blocker), which is included in the attack set, but squares \textit{beyond} the blocker are excluded.
	\end{itemize}
	
	The key insight: only a subset of squares (the \textit{relevant occupancy}) actually affects the attack pattern.
	
	\subsection*{Relevant Occupancy Mask}
	
	For any square $s \in \s$ with rank $r_s = \lfloor s/8 \rfloor$ and file $f_s = s \bmod 8$, we define the following foundational bitboard masks:
	
	\begin{itemize}
		\item $ \text{RankMask}(s) := \sum \{ 2^i \mid i \in \s, \lfloor i/8 \rfloor = r_s \} $
		\item $ \text{FileMask}(s) := \sum \{ 2^i \mid i \in \s, i \bmod 8 = f_s \} $
		\item \text{DiagonalMask}($s$): The set of squares where the difference between rank and file is constant (parallel to the $a1-h8$ diagonal). $$ \text{DiagonalMask}(s) := \sum \{ 2^i \mid i \in \s, (\lfloor i/8 \rfloor - (i \bmod 8)) = (r_s - f_s) \} $$
		\item \text{AntiDiagonalMask}($s$): Same as above, but parallel to the $h1-a8$ diagonal. $$ \text{AntiDiagonalMask}(s) := \sum \{ 2^i \mid i \in \s, (\lfloor i/8 \rfloor + (i \bmod 8)) = (r_s + f_s) \} $$
		\item $ \text{Edges} := \text{RankMask}(0) \lor \text{RankMask}(56) \lor \text{FileMask}(0) \lor \text{FileMask}(7) $
	\end{itemize}
	
	For a rook on square $s \in \s$, the relevant occupancy mask $M_R(s)$ includes all squares on its rank and file, \textit{excluding} the board edges relative to the piece's rays. This is because a piece on the edge cannot block the sliding piece from reaching that edge, but it does not matter if there is a piece "behind" the edge square. $$ M_R(s) := (\text{RankMask}(s) \lor \text{FileMask}(s)) \land \neg(\text{Edges} \lor 2^s) $$ For a bishop: $$ M_B(s) := (\text{DiagonalMask}(s) \lor \text{AntiDiagonalMask}(s)) \land \neg(\text{Edges} \lor 2^s) $$
	and for a queen: $$M_Q (s) := M_R(s) \cup M_B(s)$$
	
	\subsection*{Perfect Hashing via Magic Multiplication}
	
	The magic bitboards technique uses a multiplicative hash function \cite{multiplicativehashing}. For each square $s \in \s$, we find a magic number $\mu_s \in \mathbb{Z}_{2^{64}}$ such that:
	$$ h(s, O) = \frac{(O \land M(s)) \times \mu_s}{2^{64-n(s)}} $$
	
	where:
	\begin{itemize}
		\item $M(s)$ is the relevant occupancy mask for square $s$ (drop subscripts $R, B, Q$ for simplicity).
		\item $n(s) = |M(s)|$ is the number of relevant occupancy bits.
		\item $h(s, O) \in [0, 2^{n(s)}-1]$ is the hash index.
	\end{itemize}
	
	\subsection*{Attack Lookup}
	
	The complete lookup becomes:
	$$ A(s, O) = \text{AttackTable}_s\left[\frac{(O \land M(s)) \times \mu_s}{2^{64-n(s)}}\right] $$
	
	where $\text{AttackTable}_s$ is a pre-computed array of size $2^{n(s)}$ containing all possible attack patterns for square $s$ given different occupancies.
	
	\subsection*{Finding Magic Numbers}
	
	Magic numbers are found through brute-force trial-and-error search:
	
	\begin{algorithm}
		\caption{Finding Magic Numbers for Square $s$}
		\begin{algorithmic}[1]
			\Require Square $s \in \s$, Relevant occupancy mask $M(s)$, Number of bits $n(s)|$
			\Ensure Valid magic number $\mu_s$ and populated attack table $\text{AttackTable}_s$
			\State Initialize $\text{AttackTable}_s$ as empty array of size $2^{n(s)}$
			\State $\text{found} \gets \texttt{false}$
			\While{not $\text{found}$}
			\State $\mu \gets$ random sparse 64-bit integer \Comment{Few set bits}
			\State $\text{collisionFree} \gets \texttt{true}$
			\State Clear $\text{AttackTable}_s$
			\For{each occupancy pattern $O \in \mathcal{P}(M(s))$} \Comment{$2^{n(s)}$ patterns}
			\State $\text{attacks} \gets A(s, O)$ \Comment{Compute actual attacks}
			\State $\text{index} \gets \lfloor (O \land M(s)) \times \mu / 2^{64-n(s)} \rfloor$
			\If{$\text{AttackTable}_s[\text{index}]$ is empty}
			\State $\text{AttackTable}_s[\text{index}] \gets \text{attacks}$
			\ElsIf{$\text{AttackTable}_s[\text{index}] \neq \text{attacks}$}
			\State $\text{collisionFree} \gets \texttt{false}$
			\State \textbf{break} \Comment{Collision detected, try next $\mu$}
			\EndIf
			\EndFor
			\If{$\text{collisionFree}$}
			\State $\mu_s \gets \mu$
			\State $\text{found} \gets \texttt{true}$
			\EndIf
			\EndWhile
			\State \Return $\mu_s$, $\text{AttackTable}_s$
		\end{algorithmic}
	\end{algorithm}
	
	Candidates $\mu$ are typically chosen as random 64-bit integers with few set bits (sparse), as these tend to produce better hash distributions.
	
	\section{Minimax Algorithm with Alpha-Beta Pruning}
	
	\subsection*{Purpose}
	
	Minimax \cite{knuth1975} is the foundational search algorithm for two-player zero-sum games like chess. It explores the game tree to find the optimal move by assuming both players play perfectly. The algorithm alternates between maximizing and minimizing players, evaluating positions at leaf nodes. Alpha-beta pruning is a critical optimization that eliminates branches that cannot influence the final decision, often reducing the effective branching factor from $b$ to $\sqrt{b}$.
	
	\subsection*{Game Tree Formalism}
	
	Define a game tree $\mathcal{T} = (V, E)$ where:
	\begin{itemize}
		\item $V$ is the set of positions (nodes)
		\item $E \subseteq V \times V$ is the set of moves (edges)
		\item Root position $p_0 \in V$ is the current position
		\item Leaf positions $L \subseteq V$ are terminal or depth-limited positions
	\end{itemize}
	
	\subsection*{Minimax Value Function}
	
	Let $V(p, d)$ be the minimax value of position $p$ at remaining depth $d$. Define recursively:
	
	$$ V(p, d) = \begin{cases}
			\text{eval}(p) & \text{if } d = 0 \text{ or } p \in L \\
			\displaystyle\max_{m \in M(p)} V(m(p), d-1) & \text{if } p \text{ is MAX node} \\
			\displaystyle\min_{m \in M(p)} V(m(p), d-1) & \text{if } p \text{ is MIN node}
		\end{cases} $$
	
	where:
	\begin{itemize}
		\item $M(p)$ is the set of legal moves in position $p$
		\item $m(p)$ denotes the position after applying move $m$ to position $p$
		\item $\text{eval}(p) \in \mathbb{R}$ is the static evaluation function
		\item MAX nodes correspond to the side trying to maximize the score
		\item MIN nodes correspond to the side trying to minimize the score
	\end{itemize}
	
	\subsection*{Alpha-Beta Pruning}
	
	Alpha-beta maintains two bounds during search:
	
	\begin{itemize}
		\item $\alpha$ $\gets$ Best value the maximizer can guarantee so far (lower bound)
		\item $\beta$ $\gets$ Best value the minimizer can guarantee so far (upper bound)
	\end{itemize}
	
	Initially: 
	\begin{itemize}
		\item $\alpha = -\infty$
		\item $\beta = +\infty$
	\end{itemize}
	
	The search window $[\alpha, \beta]$ narrows as the search progresses. When $\alpha \geq \beta$, the current branch can be pruned.
	
	\subsection*{Alpha-Beta Algorithm}
	
	The enhanced minimax with alpha-beta pruning:
	
	$$ V_{AB}(p, d, \alpha, \beta) = \begin{cases}
			\text{eval}(p) & \text{if } d = 0 \text{ or } p \in L \\
			\text{MaxValue}(p, d, \alpha, \beta) & \text{if MAX node} \\
			\text{MinValue}(p, d, \alpha, \beta) & \text{if MIN node}
		\end{cases} $$
	
	\begin{algorithm}[H]
		\caption{MaxValue (Maximizing Player in Alpha-Beta)}
		\begin{algorithmic}[1]
			\Require Position $p$, depth $d$, bounds $\alpha$, $\beta$
			\Ensure Best value $v$ for maximizing player
			\State $v \gets -\infty$
			\For{each move $m \in M(p)$}
			\State $v \gets \max(v, V_{AB}(m(p), d-1, \alpha, \beta))$
			\State $\alpha \gets \max(\alpha, v)$
			\If{$\beta \leq \alpha$}
			\State \textbf{break} \Comment{$\beta$-cutoff: position too good, opponent won't allow it}
			\EndIf
			\EndFor
			\State \Return $v$
		\end{algorithmic}
	\end{algorithm}
	
	\begin{algorithm}[H]
		\caption{MinValue (Minimizing Player in Alpha-Beta)}
		\begin{algorithmic}[1]
			\Require Position $p$, depth $d$, bounds $\alpha$, $\beta$
			\Ensure Best value $v$ for minimizing player
			\State $v \gets +\infty$
			\For{each move $m \in M(p)$}
			\State $v \gets \min(v, V_{AB}(m(p), d-1, \alpha, \beta))$
			\State $\beta \gets \min(\beta, v)$
			\If{$\beta \leq \alpha$}
			\State \textbf{break} \Comment{$\alpha$-cutoff: position too bad, we have better alternative}
			\EndIf
			\EndFor
			\State \Return $v$
		\end{algorithmic}
	\end{algorithm}
	
	\subsection*{Pruning Conditions}
	
	\begin{itemize}
		\item \textbf{Beta Cutoff} (at MAX node): When $v \geq \beta$, the current position is too good for the maximizer; the minimizer will avoid this branch by choosing a different move earlier.
		\item \textbf{Alpha Cutoff} (at MIN node): When $v \leq \alpha$, the current position is too good for the minimizer; the maximizer will avoid this branch.
	\end{itemize}
	
	Formally, a branch rooted at position $p$ can be pruned when:
	$$ \beta \leq \alpha \implies \text{prune}(p) $$
	
	\subsection*{Correctness and Efficiency}
	
	\textbf{Correctness}: Alpha-beta returns the same value as minimax:
	$$ V_{AB}(p, d, -\infty, +\infty) = V(p, d) \quad \forall p, d $$
	
	\textbf{Best-case efficiency}: With perfect move ordering (best move searched first), alpha-beta examines:
	$$ N_{best} = O(b^{d/2}) $$
	
	nodes instead of minimax's $O(b^d)$, effectively doubling the search depth.
	
	\textbf{Worst-case efficiency}: With worst move ordering (best move searched last):
	$$ N_{worst} = O(b^d) $$
	
	This highlights the critical importance of move ordering.
	
	\subsection*{The Evaluation Function: Implementing $\text{eval}(p)$}
	
	The static evaluation function $\text{eval}(p) \in \mathbb{R}$ quantifies the material and positional advantage for a given position $p$, relative to the side to move. While modern engines like Stockfish utilize Neural Networks (NNUE) \cite{nnue}, a standard classical implementation (as well as my implementation \cite{repo}) uses a linear combination of heuristics.
	
	\subsubsection*{Logic and Components}
	The function is typically structured as a weighted sum of various features:
	$$ \text{eval}(p) = \text{MaterialScore} + \text{PositionalScore} + \text{MobilityScore} $$
	
	\begin{enumerate}
		\item \textbf{Material Score}: Calculated using standard relative piece values. Let $v_\tau$ be the value assigned to each piece type $\tau \in \mathcal{P}$. These values represent the theoretical strength of a piece in centipawns (a unit of measurement in computer chess equivalent to $\frac{1}{100}$-th of a pawn, used to quantify positional advantages and engine evaluations). The total material score is defined as: $$ \text{MaterialScore} = \sum_{\tau \in \mathcal{P}} v_\tau (|B_{\tau,w}| - |B_{\tau,b}|) $$ where $|B|$ denotes the \textit{Hamming weight} (or population count) of the bitboard: $$ |B| = \sum_{i=0}^{63} B \land 2^i $$
		\item \textbf{Positional Score (Piece-Square Tables)}: $E_{\text{PST}}(p)$. Assigns specific values to squares based on the piece type and game phase (opening vs. endgame). For example, Knights are prioritized in the center, while King safety is weighted more heavily in the opening.
		\item \textbf{Mobility Score}: Measures the number of legal or pseudo-legal moves available, rewarding positions with greater freedom.
	\end{enumerate}
	
	\subsubsection*{Standard and Advanced Weights}
	Standard simplified weights (in centipawns) are:
	\begin{center}
		\begin{tabular}{cccccc}
			\toprule
			\textbf{Pawn} & \textbf{Knight} & \textbf{Bishop} & \textbf{Rook} & \textbf{Queen} & \textbf{King} \\
			\midrule
			100 & 320 & 330 & 500 & 900 & 20000 \\
			\bottomrule
		\end{tabular}
	\end{center}
	
	More advanced engines, such as Stockfish (pre-NNUE), use sophisticated "tapered evaluation" \cite{taperedeval} which interpolates weights between the middle-game and endgame to account for changing piece values as the board clears.
	
	\section{Move Generation}
	
	\subsection*{Purpose}
	Move generation is the process of enumerating the complete set of moves $M(p)$ for a position $p$. We employ a two-stage process: first generating \textit{pseudo-legal} moves ($M_{\text{pseudo}}$) based on piece rules, then filtering for \textit{legal} moves ($M_{\text{legal}}$) that do not leave the side to move in check.
	
	\subsection*{Pseudo-Legal Move Generation}
	For the side to move with color $c \in \mathcal{C}$, we iterate through all piece types $\tau \in \mathcal{P}$. For each square $s \in \mathcal{S}$ where bit $s$ is set in $B_{\tau,c}$, we generate moves to target squares $t$:
	$$ M_{\text{pseudo}}(s, \tau, c) = \{ (s, t, f) \mid t \in A_\tau(s, O) \land t \notin \text{Occupied}_c \} $$
	
	where $A_\tau(s, O)$ is the attack bitboard for type $\tau$, and $f$ encodes metadata such as captures ($x$) or promotion ($=$). Define $\neg c := (c = w) \, ? \, b : w$.
	
	\subsection*{Attack Generation by Piece Type}
	\begin{enumerate}
		\item \textbf{Pawns}: Unlike other pieces, pawn moves depend on color $c$. 
		\begin{itemize}
			\item \textit{Single Push}: $\text{NorthOne}(2^s) \land \neg O$.
			\item \textit{Double Push}: $\text{NorthOne}(\text{NorthOne}(2^s)) \land \neg O$ (if $s$ is on Rank 2).
			\item \textit{Captures}: $(\text{NorthWest}(2^s) \lor \text{NorthEast}(2^s)) \land \text{Occupied}_{\neg c}$.
		\end{itemize}
		\item \textbf{Leaping Pieces (Knight/King)}: Targets are retrieved from pre-computed tables (based on their move patterns):
		$$ A_N(s) = \text{KnightTable}[s], \quad A_K(s) = \text{KingTable}[s] $$
		\item \textbf{Sliding Pieces (Bishop/Rook/Queen)}: Targets are retrieved using the Magic Bitboard lookup defined in Section 3:
		$$ A_\tau(s, O) = \text{AttackTable}_{\tau,s}\left[h(s, O)\right] $$
	\end{enumerate}
	
	\subsection*{Legal Move Filtering}
	A move $m$ is legal if the resulting position $m(p)$ is not in check for color $c$:
	$$ M_{\text{legal}}(p) = \{ m \in M_{\text{pseudo}}(p) \mid \neg\text{inCheck}(m(p), c) \} $$
	
	The $\text{inCheck}(p, c)$ condition is true if the king of color $c$, located at $s_K = \text{BSF}(B_{K,c})$, is attacked by any opposing piece. $B_{\tau, \neg c}$ represents the set of all squares occupied by the opponent's pieces of type $\tau$:
	$$ \text{inCheck}(p, c) \iff \bigvee_{\tau \in \mathcal{P}} (A_\tau(s_K, O) \cap B_{\tau, \neg c}) \neq \emptyset $$
	
	\section{Zobrist Hashing}
	
	\subsection*{Purpose}
	Zobrist hashing $h : \s \to \mathbb{Z}_{2^{64}}$ \cite{zobrist1970} maps a chess position $p$ to a 64-bit integer $h(p) \in \{0, \dots, 2^{64}-1\}$. This enables $O(1)$ transposition table lookups and threefold repetition detection via incremental updates.
	
	\subsection*{Hash Function Design}
	We define a table of 781 unique, pre-generated random 64-bit constants. $Z$ stands for "Zobrist Table" or "Zobrist Constant":
	\begin{itemize}
		\item $Z_{\tau,c,s}$: One constant for each piece $\tau$, color $c$, and square $s \in \mathcal{S}$ ($6 \times 2 \times 64 = 768$).
		\item $Z_{\text{ep},f}$: One constant for each file $f \in \{0, \dots, 7\}$ where an en passant capture might be possible.
		\item $Z_{\text{castle},r}$: One constant for each castling right $r \in \{\text{WK, WQ, BK, BQ}\}$.
		\item $Z_{\text{side}}$: A single constant used to indicate it is Black's turn to move.
	\end{itemize}
	
	\subsection*{Complete Hash Computation}
	For a position $p$, the Zobrist hash is computed by XORing the constants corresponding to the features present in the position:
	$$ h(p) = \left( \bigoplus_{s \in B_{\tau,c}} Z_{\tau,c,s} \right) \oplus \left( \bigoplus_{r \in R(p)} Z_{\text{castle},r} \right) \oplus h_{\text{ep}}(p) \oplus h_{\text{side}}(p) $$
	
	where the conditional terms are defined as:
	$$ h_{\text{ep}}(p) = 
		\begin{cases} 
			Z_{\text{ep},f} & \text{if en passant is available on file } f \\
			0 & \text{otherwise}
		\end{cases} $$
	$$ h_{\text{side}}(p) = 
		\begin{cases} 
			Z_{\text{side}} & \text{if side to move is Black} \\
			0 & \text{if side to move is White}
		\end{cases} $$
	
	\subsection*{Hash Collision Analysis}
	
	The probability of collisions in a Zobrist hash table is an application of the \textit{Birthday Problem}. Consider a table containing a set of $k$ distinct chess positions $\{p_1, p_2, \dots, p_k\}$.
	
	\subsubsection*{Derivation of Expected Collisions}
	
	A collision occurs when a pair of distinct positions $(p_i, p_j)$ results in the same hash value: $h(p_i) = h(p_j)$. 
	\begin{enumerate}
		\item \textbf{Probability of a Single Pair Colliding:} Since each hash is a uniformly distributed random 64-bit integer, the probability that any two specific positions collide is:
		$$ P(h(p_i) = h(p_j)) = \frac{1}{2^{64}} $$
		\item \textbf{Number of Possible Pairs:} In a set of $k$ positions, the number of unique pairs $(p_i, p_j)$ we can form is given by the binomial coefficient $\binom{k}{2}$:
		$$ \binom{k}{2} = \frac{k(k-1)}{2} = \frac{k^2 - k}{2} $$
		\item \textbf{Linearity of Expectation:} Let $X_{i,j} = \textbf{1}_{h(p_i) = h(p_j)}$. The total number of collisions is $C = \sum X_{i,j}$. By the linearity of expectation:
		$$ \E[C] = \sum \E[X_{i,j}] = \binom{k}{2} \times \frac{1}{2^{64}} = \frac{k^2 - k}{2 \cdot 2^{64}} = \frac{k^2 - k}{2^{65}} $$
	\end{enumerate}
	
	For a standard transposition table size of $k = 2^{24} = 16,777,216$, the expected number of collisions is:
	$$ \E[C] = \frac{(2^{24})^2 - 2^{24}}{2^{65}} = \frac{2^{24} (2^{24} - 1)}{2^{65}} = \frac{2^{24} - 1}{2^{41}} $$
	Expanding the fraction:
	$$ \E[C] = \frac{2^{24}}{2^{41}} - \frac{1}{2^{41}} = 2^{-17} - 2^{-41} \approx 0.0000076 $$
	
	This means that in a search tree of over 16 million nodes, there is only a $\approx 0.00076\%$ chance of seeing even \textit{one} collision. Seems reasonable enough for me.
	
	\subsection*{The Transposition Table}
	The Transposition Table (TT) is a large hash table that stores search results to avoid re-evaluating the same positions reached via different move orders (transpositions).
	
	\subsubsection*{Entry Structure}
	Each entry in the table typically occupies 128 bits and contains the following data:
	\begin{itemize}
		\item \textbf{Key}: The full 64-bit Zobrist hash (to verify no collisions).
		\item \textbf{Score}: The evaluation value $v$ found during search.
		\item \textbf{Depth}: The remaining search depth at which this score was found.
		\item \textbf{Flag}: Indicates if the score is an \textit{Exact} value, a \textit{Lower Bound} ($\beta$-cutoff), or an \textit{Upper Bound} ($\alpha$-cutoff).
		\item \textbf{Best Move}: The move that achieved this score, used to seed the next search's move ordering.
	\end{itemize}
	
	\subsubsection*{Replacement Strategy}
	Since the number of possible chess positions far exceeds the table size, we use a replacement strategy. When a collision occurs at an index, the engine typically uses a \textbf{Depth-Preferred} approach: the new entry overwrites the old one only if the new search depth is greater than or equal to the stored depth.
	
	\section{Principal Variation}
	
	\subsection*{Purpose}
	The Principal Variation is the sequence of moves that the engine considers to be the best play for both sides. It represents the "main line" of the game at any given search depth.
	
	$$ \text{PV} = \langle m_1, m_2, \dots, m_d \rangle $$
	
	\newpage
	Tracking this sequence is essential for two reasons:
	\begin{itemize}
		\item \textbf{User Feedback}: It shows the user what the engine is "thinking" and how it justifies its evaluation.
		\item \textbf{Search Stability}: It allows the engine to use an \textit{Aspiration Window}, assuming the score of the current search will not deviate drastically from the score of the previous PV.
	\end{itemize}
	
	\subsection*{Formal Definition}
	
	Let $p$ be a position and $d$ be the search depth. We denote $m(p)$ as the position resulting from applying move $m \in M(p)$ to position $p$. The PV is defined recursively as the sequence starting with the best move $m^*$, concatenated with the PV of the resulting position $m^*(p)$:
	
	$$ \text{PV}(p, d) = \begin{cases} \langle \rangle & \text{if } d = 0 \text{ or } p \text{ is terminal} \\ \langle m^* \rangle \circ \text{PV}(m^*(p), d-1) & \text{otherwise} \end{cases} $$
	
	The best move $m^*$ is the one that leads to the state with the highest (or lowest) minimax value. Using our previously defined operators:
	
	$$ m^* = \begin{cases} 
		\argmax_{m \in M(p)} \{ V_{AB}(m(p), d-1, \alpha, \beta) \} & \text{if MAX node} \\
		\argmin_{m \in M(p)} \{ V_{AB}(m(p), d-1, \alpha, \beta) \} & \text{if MIN node} 
	\end{cases} $$
	
	where $\circ$ denotes the sequence concatenation operator. In this framework, $m^*(p)$ represents the board state that the opponent will face at the next ply (distance from root) of the search.
	
	\subsection*{The Triangular PV Array}
	In a recursive Alpha-Beta search, maintaining the PV can be computationally expensive if using dynamic lists. Instead, engines use a \textbf{Triangular Array}, a structure where each ply has its own move buffer.
	
	Define the array $\mathbf{PV}[D \times D]$, where $D$ is the maximum search depth. If a move $m$ improves $\alpha$ (causing a "PV-node" update), we update the array for the current ply $i$:
	
	\begin{algorithm}[H]
		\caption{Update Principal Variation}
		\begin{algorithmic}[1]
			\Require Current ply $i$, better move $m$ found at depth $d$, child PV at ply $i+1$
			\Ensure Updated PV at ply $i$
			\State $\mathbf{PV}[i][i] \gets m$ \Comment{Store current best move}
			\For{$j \gets i+1$ to $\text{length}(\mathbf{PV}[i+1])$}
			\State $\mathbf{PV}[i][j] \gets \mathbf{PV}[i+1][j]$ \Comment{Copy the continuation from the child}
			\EndFor
		\end{algorithmic}
	\end{algorithm}
	
	By the time the search returns to the root (ply 0), the first row of the triangle $\mathbf{PV}[0][0 \dots d-1]$ contains the full Principal Variation.
	
	\subsection*{PV-Move Ordering}
	
	The most critical application of the PV is in \textbf{Move Ordering} during iterative deepening. If we have completed a search at depth $d$, the first move we should search in the next iteration (depth $d+1$) is the best move from the previous iteration. We denote the Principal Variation found at depth $d$ as $\text{PV}_d$.
	
	Searching $\text{PV}_d[0]$ (the first move of the previous best line) maximizes the probability of an early Alpha-Beta cutoff. We define the priority function for a move $m \in M(p)$ at iteration $d+1$ as:
	
	$$ \text{Priority}(m) = \begin{cases} \infty & \text{if } m = \text{PV}_d[0] \\ \text{HeuristicScore}(m) & \text{otherwise} \end{cases} $$
	
	\subsection*{PV Stability and Aspiration}
	
	The efficiency of iterative deepening relies on \textbf{PV Stability}. We define this property as the probability that the Principal Variation at depth $d$ remains a prefix of the Principal Variation at depth $d+1$:
	$$ \text{Stability}(d) = \mathbb{P} \left( \text{PV}_d[0 \dots k] = \text{PV}_{d+1}[0 \dots k] \right) $$
	where $k$ is the number of consistent moves (the "prefix length"). In stable positions, $k \geq 1$ with high probability. 
	
	When stability is high, we can utilize an \textbf{Aspiration Window}. Instead of searching the interval $(-\infty, \infty)$, we assume the new evaluation $V_{d+1}$ will be close to the previous evaluation $V_d$. We define a search margin $\epsilon \in \mathbb{R}^+$, representing the maximum expected fluctuation in the position's value. 
	
	We initialize the Alpha-Beta bounds as:
	$$ \alpha = V_d - \epsilon, \quad \beta = V_d + \epsilon $$
	
	If the search concludes with a score $V \in (\alpha, \beta)$, the result is valid and was found significantly faster due to the narrower window. However, we must handle two edge cases:
	\begin{itemize}
		\item \textbf{Fail Low}: If $V \leq \alpha$, the position is worse than expected. We must re-search with $[-\infty, \alpha]$.
		\item \textbf{Fail High}: If $V \geq \beta$, the position is better than expected. We must re-search with $[\beta, \infty]$.
	\end{itemize}
	
	\section{Piece-Square Tables}
	
	\subsection*{Purpose}
	Piece-square tables (PSTs) encode positional knowledge by assigning a numerical value to each piece on each square. They enable the engine to differentiate between a Knight in the center (active) and a Knight on the edge (passive) without expensive geometric calculations. The total PST contribution, denoted as $E_{\text{PST}}(p)$, is the primary component of the positional evaluation in $\text{eval}(p)$.
	
	\subsection*{Formalism}
	For each piece type $\tau \in \mathcal{P}$ and each square $s \in \s$, we define a static weight $\text{PST}_\tau[s] \in \mathbb{Z}$. These values are predefined constants. The total contribution is:
	
	$$ E_{\text{PST}}(p) = \sum_{c \in \{w,b\}} \sigma(c) \sum_{\tau \in \mathcal{P}} \sum_{s \in S_{\tau,c}(p)} \text{PST}_\tau[s] $$
	
	where $\sigma(w) = 1$ and $\sigma(b) = -1$. The initial value for a position $p$ is calculated by iterating over all squares $s \in \mathcal{S}$ and summing the values of the pieces found.
	
	\subsection*{Game Phase Interpolation}
	King safety is critical in the middlegame but centralization is key in the endgame. We interpolate between two tables, $\text{PST}_{K}^{\text{mg}}$ and $\text{PST}_{K}^{\text{eg}}$, using a phase factor $\phi \in [0, 1]$:
	
	$$ \text{PST}_K[s] = (1 - \phi) \cdot \text{PST}_{K}^{\text{mg}}[s] + \phi \cdot \text{PST}_{K}^{\text{eg}}[s] $$
	
	The phase $\phi$ is determined by the total non-pawn material currently on the board:
	$$ \phi = 1 - \frac{\text{NonPawnMaterial}(p)}{\text{NonPawnMaterial}_{\text{start}}} $$
	
	where $\text{NonPawnMaterial}(p) = \sum_{c \in \mathcal{C}} \sum_{\tau \in \mathcal{P} \setminus \{P\}} v_\tau |B_{\tau,c}|$. At the start of a game, $\text{NonPawnMaterial}_{\text{start}}$ is usually 6400 centipawns. As pieces are traded, $\phi$ approaches 1 (Endgame).
	
	\subsection*{Incremental PST Updates}
	To avoid re-summing the entire board, we update the PST score after every move $m: s_1 \to s_2$. If a piece $\tau$ of color $c$ moves:
	
	$$ \Delta_{\text{PST}}(m) = \sigma(c) \left(\text{PST}_\tau[s_2] - \text{PST}_\tau[s_1]\right) + \text{capture-bonus} $$
	
	The $\text{capture-bonus}$ ensures the evaluation is corrected for a piece removed from the board. If a piece of type $\tau_{cap}$ and color $\neg c$ was captured at $s_2$:
	
	$$ \text{capture-bonus} = -\sigma(\neg c) \cdot \text{PST}_{\tau_{cap}}[s_2] $$
	
	Note that because $\sigma(\neg c)$ is the opposite of $\sigma(c)$, this effectively becomes:
	$$ \text{capture-bonus} = \sigma(c) \cdot \text{PST}_{\tau_{cap}}[s_2] $$
	
	\subsection*{Symmetry for Black Pieces}
	To save memory, we only store PSTs for White. Black's values are derived by mirroring the square vertically:
	$$ \text{PST}_{\tau, b}[s] = \text{PST}_{\tau, w}[s \oplus 56] $$
	
	\section{Move Ordering}
	
	\subsection*{Purpose}
	The efficiency of Alpha-Beta pruning is highly dependent on the order in which moves are searched. If the best move (the move that produces the highest evaluation) is searched first, the search window $[\alpha, \beta]$ narrows immediately, allowing the algorithm to prune the maximum number of subtrees. In the best-case scenario, perfect ordering reduces the search complexity from $O(b^d)$ to $O(b^{d/2})$.	
	
	\subsection*{Heuristic Scoring Function}
	We define a scoring function $S(m, p, i)$ that assigns a numerical priority to each move $m \in M_{\text{pseudo}}(p)$ at ply $i$. Before searching, moves are sorted in descending order of $S$. We define $S(m, p, i)$ to show that move priority depends on the position $p$ and the current ply $i$, but we use $S(m)$ as a shorthand during sorting because the context of $p$ and $i$ is constant for all moves being considered at a specific node.
	
	
	\subsubsection*{1. The Hash Move}
	If the Transposition Table contains an entry for the current position $h(p)$, the move that was previously stored as the best move in that entry is assigned the highest priority.
	$$S(m) = 10^7 \quad \text{if } m \text{ matches the stored move for } h(p)$$
	
	\subsubsection*{2. MVV-LVA (Most Valuable Victim - Least Valuable Attacker)}
	For capture moves, we prioritize those that capture high-value pieces with low-value attackers. For a move $m$ where piece $\tau_a$ captures $\tau_v$:
	$$S(m) = 10^6 + (10 \cdot v_{\tau_v} - v_{\tau_a})$$
	This requires no initialization as piece values are static constants.
	
	\subsubsection*{3. Killer Heuristic}
	Killer moves are quiet moves (non-captures) that caused a beta-cutoff in a different branch at the same ply $i$. A table $\text{Killers}[i][0 \dots 1]$ initialized to $0$ for all plies.
	$$S(m) = \begin{cases} 10^5 & \text{if } m = \text{Killers}[i][0] \\ 10^4 & \text{if } m = \text{Killers}[i][1] \end{cases}$$
	
	\subsubsection*{4. History Heuristic}
	The history heuristic tracks the success of quiet moves globally. A table $\text{History}[2][64][64]$ initialized to zero. When a quiet move $m: s_1 \to s_2$ causes a cutoff at depth $d$, we increment the score:
	$$\text{History}[c][s_1][s_2] \gets \text{History}[c][s_1][s_2] + d^2$$
	
	\section{The Optimized Search Framework}
	
	\subsection*{The Unified Alpha-Beta Algorithm}
	This implementation utilizes the \textbf{Negamax} formulation and integrates the Transposition Table logic using the hash $h(p)$.
	
	\section*{Negamax Search and Transposition Table Integration}
	The search engine utilizes the \textbf{Negamax} formulation, a variant of Minimax that simplifies implementation by exploiting the mathematical property $$\max(a, b) = -\min(-a, -b)$$ This allows a single function to handle both players by negating the scores returned by recursive calls. To optimize performance, we integrate the Transposition Table (TT) directly into the search flow using the Zobrist hash $h(p)$. Before move generation, the engine performs a TT lookup to check for previously searched results that might allow for an immediate cutoff
	
	\begin{algorithm}
		\caption{Modern Alpha-Beta Search}
		\begin{algorithmic}[1]
			\Require Position $p$, depth $d$, bounds $[\alpha, \beta]$, ply $i$
			\Ensure Evaluation $v$
			\State $h \gets h(p)$
			\State $entry \gets \text{lookupTranspositionTable}(h)$
			\If{$entry.\text{depth} \geq d$} \Comment{Transposition Table Cutoff}
			\If{$entry.\text{flag} = \text{EXACT}$} \Return $entry.\text{score}$
			\ElsIf{$entry.\text{flag} = \text{LOWER}$} $\alpha \gets \max(\alpha, entry.\text{score})$
			\ElsIf{$entry.\text{flag} = \text{UPPER}$} $\beta \gets \min(\beta, entry.\text{score})$
			\EndIf
			\If{$\alpha \geq \beta$} \Return $entry.\text{score}$ \EndIf
			\EndIf
			
			\State \textbf{Base Case}: If $d = 0$, \Return $\text{QuiescenceSearch}(p, \alpha, \beta)$
			
			\State $v \gets -\infty$, $bestM \gets \text{null}$, $moveCount \gets 0$
			\State $M \gets \text{OrderMoves}(M_{\text{pseudo}}(p), S)$
			
			\For{each $m \in M$}
			\If{$\text{isLegal}(m, p)$}
			\State $moveCount \gets moveCount + 1$
			\State $v_{cur} \gets -V_{AB}(m(p), d-1, -\beta, -\alpha, i+1)$
			\If{$v_{cur} > v$}
			\State $v \gets v_{cur}, bestM \gets m$
			\If{$v > \alpha$} $\alpha \gets v$ \EndIf
			\If{$\alpha \geq \beta$} 
			\State \textbf{UpdateKillersAndHistory}(m, d, i)
			\State \textbf{break} \Comment{Beta Cutoff}
			\EndIf
			\EndIf
			\EndIf
			\EndFor
			
			\If{$moveCount = 0$} \Return $\text{evaluateTerminalNode}(p)$ \EndIf
			
			\State \textbf{StoreEntry}(hash: $h$, score: $v$, depth: $d$, move: $bestM$, flag: $\text{getFlag}(\alpha, \beta, v)$)
			\State \Return $v$
		\end{algorithmic}
	\end{algorithm}
	
	\subsection*{Iterative Deepening and Aspiration}
	The search is driven by an outer loop increasing depth $d$. We use an \textbf{Aspiration Window} around the previous result $V_d$:
	$$\alpha = V_d - \epsilon, \quad \beta = V_d + \epsilon$$
	If the result $V_{d+1}$ falls outside $(\alpha, \beta)$, we widen the window and re-search.
	
	\newpage
	\begin{thebibliography}{9}
		
		\bibitem{cpw}
		Chess Programming Wiki.
		\textit{Chess Programming Wiki}.
		Accessed February 2026.
		\href{https://www.chessprogramming.org/}{https://www.chessprogramming.org/}
		
		\bibitem{knuth1975}
		Knuth, D. E., \& Moore, R. W. (1975).
		\textit{An analysis of alpha-beta pruning}.
		Artificial Intelligence, 6(4), 293-326.
		\href{https://doi.org/10.1016/0004-3702(75)90019-3}{https://doi.org/10.1016/0004-3702(75)90019-3}
		
		\bibitem{mediocrechess}
		Jonatan Pettersson.
		\textit{Mediocre Chess: Guide to Writing a Chess Engine}.
		\href{https://mediocrechess.blogspot.com/}{https://mediocrechess.blogspot.com/}
		
		\bibitem{perfecthashing}
		Wikipedia. \href{https://en.wikipedia.org/wiki/Perfect_hash_function}{Perfect Hash Function}
		
		\bibitem{multiplicativehashing}
		\textit{Lecture 21: Hash Functions and Hash Tables}.
		CS 3110: Data Structures and Functional Programming, Cornell University.
		\href{https://www.cs.cornell.edu/courses/cs3110/2008fa/lectures/lec21.html}{https://www.cs.cornell.edu/courses/cs3110/2008fa/lectures/lec21.html}
		
		\bibitem{nnue}
		\textit{Introducing NNUE Evaluation}. \href{https://stockfishchess.org/blog/2020/introducing-nnue-evaluation/}{stockfishchess.org}
		
		\bibitem{taperedeval}
		\textit{Tapered Evaluation (pre-NNUE)}.
		\href{https://www.chessprogramming.org/Tapered_Eval}{Chess Programming Wiki}
		
		\bibitem{zobrist1970}
		Zobrist, A. L. (1970).
		\textit{A new hashing method with application for game playing}.
		Technical Report 88, Computer Sciences Department, University of Wisconsin, Madison, Wisconsin.
		\href{https://minds.wisconsin.edu/handle/1793/57624}{Minds @ UW}
		
		\bibitem{shannon1950}
		Shannon, C. E. (1950).
		\textit{Programming a computer for playing chess}.
		The London, Edinburgh, and Dublin Philosophical Magazine and Journal of Science, 41(314), 256-275.
		\href{https://doi.org/10.1080/14786445008521796}{https://doi.org/10.1080/14786445008521796}
		
		\bibitem{bitboards}
		\textit{Rotated Bitboards}.
		\href{https://www.chessprogramming.org/Rotated_Bitboards}{Chess Programming Wiki}
		
		\bibitem{magicbitboards}
		\textit{Magic Bitboards}.
		\href{https://www.chessprogramming.org/Magic_Bitboards}{Chess Programming Wiki}
		
		\bibitem{repo}
		\textit{GitHub Repository}.
		\href{https://github.com/Stochastic-Batman/Zugzwang.git}{Zugzwang}
		
	\end{thebibliography}
	
\end{document}
